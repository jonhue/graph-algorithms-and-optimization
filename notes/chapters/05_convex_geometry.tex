% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Convex Geometry}

We want to develop a better understanding of optimization problems. The general form of an \emph{optimization problem}\index{optimization problem} is, \begin{align}
    \min_{\substack{\vy \in \R^n \\ \vg(\vy) \leq \vb}} f(\vy), \label{eq:optimization_problem}
\end{align} where $f : \R^n \to \R$ is the function to be minimized, $\vg : \R^n \to \R^m$ is a vector-valued function of $m$ constraints with thresholds $\vb \in \R^m$.\footnote{It suffices to consider minimization problems. If we want to maximize a function $f$, this is equivalent to minimizing the function $-f$.}

\begin{defn}[Feasible set] We call \begin{align}
    \spa{F} \defeq \{\vx \in \R^n \mid \vg(\vx) \leq \vb\}
\end{align} the \emph{feasible set}\index{feasible set}. We call \begin{itemize}
    \item $\vx \in \spa{F}$ a \emph{feasible point}\index{feasible point}; and
    \item $\vx \not\in \spa{F}$ an \emph{infeasible point}\index{infeasible point}.
\end{itemize}
\end{defn}
\begin{defn}[Optimal solution] We say that $\s{\vx} \in \R^n$ is \emph{optimal}\index{optimal point} if $\s{\vx} \in \spa{F}$ and $\forall \vx \in \spa{F}: f(\s{\vx}) \leq f(\vx)$.
\end{defn}
\begin{marginfigure}
\includegraphics[width=\textwidth]{notes/figures/no_opt.png}
\caption{Examples of optimization problems without an optimal solution.}
\end{marginfigure}

Let us look at a sufficient condition for optimal solutions. \begin{thm}[Extreme value theorem]\index{extreme value theorem}\label{thm:extreme_value_theorem}
Let $f : \R^n \to \R$ be continuous, and let $\spa{F} \subseteq \R^n$ be non-empty, bounded, and closed. Then, $f$ is bounded on $\spa{F}$ and has an optimal solution.
\end{thm}

\section{Convex Sets \& Functions}

\begin{defn}[Convex set] A set $\sS \subseteq \R^n$ is \emph{convex}\index{convex set} iff \begin{align}
    \forall \vx, \vy \in \sS: \forall \theta \in [0,1]: \theta\vx + (1-\theta)\vy \in \sS.
\end{align}
\end{defn}
\begin{marginfigure}
\centering\includegraphics[width=4cm]{notes/figures/convex_set.png}
\caption{Example of a non-convex and a convex set.}
\end{marginfigure}
\begin{defn}[Convex function] For a convex set $\sS \subseteq \R^n$, a function $f : \sS \to \R$ is \emph{convex}\index{convex function} on $\sS$ iff \begin{align}
    \forall \vx, \vy \in \sS: \forall \theta \in [0,1]: f(\theta\vx + (1-\theta)\vy) \leq \theta f(\vx) + (1-\theta) f(\vy).
\end{align} Similarly, we call $f$ \emph{strictly convex}\index{strictly convex function} on $\sS$ iff \begin{align}
    \forall \vx, \vy \in \sS: \forall \theta\in[0,1]: f(\theta\vx + (1-\theta)\vy) < \theta f(\vx) + (1-\theta) f(\vy).
\end{align}
\end{defn}
\begin{marginfigure}
\centering\includegraphics[width=3cm]{notes/figures/convex_function.png}
\caption{Example of a convex function. Any line between two points on $f$, lies ``above'' $f$. The epigraph of $f$ is shown in blue.}
\end{marginfigure}

\begin{rmk}
If the function $f$ is convex on $\sS$, we say that the function $-f$ is \emph{concave}\index{concave function} on $\sS$.
\end{rmk}

\begin{rmk}
We call the optimization problem from \cref{eq:optimization_problem} \emph{convex}\index{convex optimization} iff $f$ and $g_i$ are convex functions. Sometimes it is useful to equivalently write \begin{align}
    \min_{\vy \in \sS} f(\vy) \quad\text{for }\sS \defeq \{\vy \in \R^n \mid \vg(\vy) \leq \vb\}.
\end{align} Observe that these characterizations are equivalent, as any convex set $\sS$ can be characterized in terms of convex constraints.
\end{rmk}

\begin{fct} A differentiable and convex function $f$, whose domain $\sS \subseteq \R^n$ is open and convex, is always continuously differentiable.
\end{fct} In the following, we will assume that $\sS \subseteq \R^n$ is open.

\begin{defn}[Epigraph]
The \emph{epigraph}\index{epigraph} of a function $f : \sS \to \R$ is \begin{align}
    \mathrm{epi}(f) \defeq \{(\vx,y) \mid f(\vx) \leq y\} \subseteq \R^{n+1}.
\end{align}
\end{defn}
\begin{exc}\label{exc:convex_iff_epi_convex}
The function $f : \sS \to \R$ is convex iff $\mathrm{epi}(f)$ is convex.
\end{exc}

\begin{defn}[(Sub-)level set] Given a function $f : \sS \to \R$, we call, \begin{align}
    \sS_\alpha(f) &\defeq \{\vx \in \sS \mid f(\vx) \leq \alpha\}, \\
    \sL_\alpha(f) &\defeq \{\vx \in \sS \mid f(\vx) = \alpha\},
\end{align} its \emph{$\alpha$-sub-level set}\index{sub-level set} and \emph{$\alpha$-level set}\index{level set}, respectively.
\end{defn}
\begin{exc}\label{exc:sub_level_set_of_convex_function_convex}
Any $\alpha$-sub-level set of a convex function is convex.\footnote{Note that the other direction does not hold! Take $f(x) \defeq x^3$ as an example. Functions whose sub-level sets are convex are called \emph{quasiconvex}\index{quasiconvex function}.}
\end{exc}

\section{First-order Characterization of Convexity}

\begin{marginfigure}
\centering\includegraphics[width=3cm]{notes/figures/1st_order_characterization.png}
\caption{The first-order characterization characterizes convexity in terms of affine lower bounds.}
\end{marginfigure}
\begin{thm}[First-order characterization of convexity] Consider a differentiable function $f: \sS \to \R$. Then, $f$ is convex iff \begin{align}
    f(\vy) \geq f(\vx) + \trans{\grad f(\vx)}(\vy - \vx)
\end{align} for all $\vx, \vy \in \sS$. Moreover, $f$ is strictly convex iff \begin{align}
    f(\vy) > f(\vx) + \trans{\grad f(\vx)}(\vy - \vx)
\end{align}
\end{thm}
\begin{proof} We first prove the statement about convexity. \begin{itemize}
    \item ``$\Rightarrow$'': Fix any $\vx, \vy \in \sS$. As $f$ is convex, \begin{align*}
        f((1-\theta)\vx + \theta\vy) \leq (1-\theta)f(\vx) + \theta f(\vy),
    \end{align*} for all $\theta \in [0,1]$. We can rearrange to, \begin{align*}
        f(\underbrace{(1-\theta)\vx + \theta\vy}_{\vx + \theta(\vy - \vx)}) - f(\vy) \leq \theta(f(\vx) - f(\vy)).
    \end{align*} Dividing by $\theta$ yields, \begin{align*}
        \frac{f(\vx + \theta(\vy - \vx)) - f(\vx)}{\theta} \leq f(\vy) - f(\vx).
    \end{align*} Taking the limit $\theta \to 0$ on both sides gives the directional derivative at $\vx$ in direction $\vy - \vx$, \begin{align*}
        \trans{\grad f(\vx)}(\vy - \vx) = D f(\vx)[\vy - \vx] \leq f(\vy) - f(\vx).
    \end{align*}
    
    \item ``$\Leftarrow$'': Fix any $\vx, \vy \in \sS$ and let $\vz \defeq \theta\vy + (1-\theta)\vx$. We have, \begin{align*}
        f(\vy) &\geq f(\vz) + \trans{\grad f(\vz)}(\vy - \vz), \quad\text{and} \\
        f(\vx) &\geq f(\vz) + \trans{\grad f(\vz)}(\vx - \vz).
    \end{align*} We also have $(1-\theta)(\vy-\vx) = \vy - \vz$ and $\theta(\vy - \vx) = \vx - \vz$. Hence, \begin{align*}
        \theta f(\vy) + (1-\theta) f(\vx) &\geq f(\vz) + \trans{\grad f(\vz)}(\underbrace{\theta(\vy - \vz) + (1-\theta)(\vx - \vz)}_{0}) \\
        &= f(\theta\vy + (1-\theta)\vx).
    \end{align*}
\end{itemize}

Finally, observe that the statement about strict convexity can be proven analogously by making the inequalities strict.
\end{proof}

\begin{thm} Let $f: \sS \to \R$ be a convex and differentiable function. Then, if $\vx \in \sS$ is a stationary point of $f$, then $\vx$ is a global minimum of $f$.
\end{thm}
\begin{proof} By the first-order characterization of convexity, we have for any $\vy \in \sS$, \begin{align*}
    f(\vy) \geq f(\vx) + \underbrace{\trans{\grad f(\vx)}}_{0}(\vy - \vx) = f(\vx). &\qedhere
\end{align*}
\end{proof}

\section{Second-order Characterization of Convexity}

\begin{thm}[Second-order characterization of convexity] Consider a twice continuously differentiable function $f: \sS \to \R$.\footnote{Here we need our assumption that $\sS$ is open.} \begin{enumerate}
    \item $f$ is convex iff $\mH_f(\vx)$ is positive semi-definite for all $\vx \in \sS$.
    \item $f$ is strictly convex iff $\mH_f(\vx)$ is positive definite for all $\vx \in \sS$.
\end{enumerate}
\end{thm}
\begin{proof} We first prove the statement about convexity. \begin{itemize}
    \item ``$\Leftarrow$'': Fix any $\vx, \vy \in \sS$. By the second-order form of Taylor's theorem, \begin{align*}
        f(\vy) &= f(\vx) + \trans{\grad f(\vx)}(\vy - \vx) + \frac{1}{2}\underbrace{\trans{(\vy - \vx)}\mH_f(\vz)(\vy - \vx)}_{\geq 0} \\
        &\geq f(\vx) + \trans{\grad f(\vx)}(\vy - \vx),
    \end{align*} for some $\vz \in [\vx,\vy]$. This coincides with the first-order characterization of convexity.
    
    \item ``$\Rightarrow$'': Fix any $\vx \in \sS$ and $\vd \in \R^n$. Note that, as $\sS$ is open, for small enough $\lambda \in [-\epsilon,\epsilon] \setminus \{0\}$, $\vx + \lambda\vd \in \sS$. We have, \begin{align*}
        0 &\leq f(\vx + \lambda\vd) - [f(\vx) + \lambda \trans{\grad f(\vx)}\vd] \margintag{using the first-order characterization of convexity} \\
        &= \frac{1}{2}\lambda^2\trans{\vd}\mH_f(\vx)\vd + o(\lambda^2 \norm{\vd}_2^2). \margintag{using a second-order expansion}
    \end{align*} Multiplying both sides by $\nicefrac{2}{\lambda^2}$ and taking the limit $\lambda \to 0$, we obtain, \begin{align*}
        0 \leq \trans{\vd}\mH_f(\vx)\vd + \lim_{\lambda \to 0}\frac{o(\lambda^2 \norm{\vd}_2^2)}{\lambda^2} = \trans{\vd}\mH_f(\vx)\vd.
    \end{align*}
\end{itemize}

The statement about strict convexity follows by using the first-order characterization of strict convexity instead and replacing inequalities with strict inequalities.
\end{proof}