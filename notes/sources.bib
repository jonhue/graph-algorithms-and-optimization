@article{greedy_mi,
	title        = {An analysis of approximations for maximizing submodular set functions—I},
	author       = {Nemhauser, George L and Wolsey, Laurence A and Fisher, Marshall L},
	year         = 1978,
	journal      = {Mathematical programming},
	publisher    = {Springer},
	volume       = 14,
	pages        = {265--294}
}

@article{williams1992simple,
	title        = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	author       = {Williams, Ronald J},
	year         = 1992,
	journal      = {Machine learning},
	publisher    = {Springer},
	volume       = 8,
	number       = 3,
	pages        = {229--256}
}

@article{aimodernapproach,
	title        = {Artificial intelligence: a modern approach},
	author       = {Russell, Stuart and Norvig, Peter},
	year         = 2002
}

@article{brafman2002r,
	title        = {R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
	author       = {Brafman, Ronen I and Tennenholtz, Moshe},
	year         = 2002,
	journal      = {Journal of Machine Learning Research},
	volume       = 3,
	number       = {Oct},
	pages        = {213--231}
}

@article{even2003learning,
	title        = {Learning Rates for Q-learning.},
	author       = {Even-Dar, Eyal and Mansour, Yishay and Bartlett, Peter},
	year         = 2003,
	journal      = {Journal of machine learning Research},
	volume       = 5,
	number       = 1
}

@article{ip,
	title        = {A unifying view of sparse approximate Gaussian process regression},
	author       = {Quinonero-Candela, Joaquin and Rasmussen, Carl Edward},
	year         = 2005,
	journal      = {The Journal of Machine Learning Research},
	volume       = 6
}

@book{gpml,
	title        = {Gaussian processes for machine learning},
	author       = {Williams, Christopher K and Rasmussen, Carl Edward},
	year         = 2006,
	publisher    = {MIT press},
	volume       = 2
}

@misc{praml,
	title        = {Pattern recognition and machine learning},
	author       = {Svens{\'e}n, Markus and Bishop, Christopher M},
	year         = 2007,
	publisher    = {Springer Berlin/Heidelberg, Germany}
}

@inproceedings{rff,
	title        = {Random Features for Large-Scale Kernel Machines.},
	author       = {Rahimi, Ali and Recht, Benjamin and others},
	year         = 2007,
	booktitle    = {NIPS}
}

@article{szepesvari2010algorithms,
	title        = {Algorithms for reinforcement learning},
	author       = {Szepesv{\'a}ri, Csaba},
	year         = 2010,
	journal      = {Synthesis lectures on artificial intelligence and machine learning},
	publisher    = {Morgan \& Claypool Publishers},
	volume       = 4,
	number       = 1,
	pages        = {1--103}
}

@article{ucb_regret,
	title        = {Gaussian process optimization in the bandit setting: No regret and experimental design},
	author       = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M and Seeger, Matthias},
	year         = 2010,
	booktitle    = {International Conference on Machine Learning},
	pages        = {1015–-1022},
	organization = {ICML}
}

@inproceedings{welling2011bayesian,
	title        = {Bayesian learning via stochastic gradient Langevin dynamics},
	author       = {Welling, Max and Teh, Yee W},
	year         = 2011,
	booktitle    = {Proceedings of the 28th international conference on machine learning (ICML-11)},
	pages        = {681--688},
	organization = {Citeseer}
}

@inproceedings{deisenroth2011pilco,
	title        = {PILCO: A model-based and data-efficient approach to policy search},
	author       = {Deisenroth, Marc and Rasmussen, Carl E},
	year         = 2011,
	booktitle    = {Proceedings of the 28th International Conference on machine learning (ICML-11)},
	pages        = {465--472},
	organization = {Citeseer}
}

@article{pi_convergence,
	title        = {The simplex and policy-iteration methods are strongly polynomial for the Markov decision problem with a fixed discount rate},
	author       = {Ye, Yinyu},
	year         = 2011,
	journal      = {Mathematics of Operations Research},
	publisher    = {INFORMS},
	volume       = 36,
	number       = 4,
	pages        = {593--603}
}

@inproceedings{ranganath2014black,
	title        = {Black box variational inference},
	author       = {Ranganath, Rajesh and Gerrish, Sean and Blei, David},
	year         = 2014,
	booktitle    = {Artificial intelligence and statistics},
	pages        = {814--822},
	organization = {PMLR}
}

@inproceedings{sghmc,
	title        = {Stochastic gradient hamiltonian monte carlo},
	author       = {Chen, Tianqi and Fox, Emily and Guestrin, Carlos},
	year         = 2014,
	booktitle    = {International conference on machine learning},
	pages        = {1683--1691},
	organization = {PMLR}
}

@inproceedings{titsias2014doubly,
	title        = {Doubly stochastic variational Bayes for non-conjugate inference},
	author       = {Titsias, Michalis and L{\'a}zaro-Gredilla, Miguel},
	year         = 2014,
	booktitle    = {International conference on machine learning},
	pages        = {1971--1979},
	organization = {PMLR}
}

@inproceedings{duvenaud2015black,
	title        = {Black-box stochastic variational inference in five lines of python},
	author       = {Duvenaud, David and Adams, Ryan P},
	year         = 2015,
	booktitle    = {NIPS Workshop on Black-box Learning and Inference}
}

@article{lillicrap2015continuous,
	title        = {Continuous control with deep reinforcement learning},
	author       = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1509.02971}
}

@article{schulman2015high,
	title        = {High-dimensional continuous control using generalized advantage estimation},
	author       = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1506.02438}
}

@article{mnih2015human,
	title        = {Human-level control through deep reinforcement learning},
	author       = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
	year         = 2015,
	journal      = {nature},
	publisher    = {Nature Publishing Group},
	volume       = 518,
	number       = 7540,
	pages        = {529--533}
}

@article{heess2015learning,
	title        = {Learning continuous control policies by stochastic value gradients},
	author       = {Heess, Nicolas and Wayne, Greg and Silver, David and Lillicrap, Timothy and Tassa, Yuval and Erez, Tom},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1510.09142}
}

@inproceedings{gpc,
	title        = {Scalable variational Gaussian process classification},
	author       = {Hensman, James and Matthews, Alexander and Ghahramani, Zoubin},
	year         = 2015,
	booktitle    = {Artificial Intelligence and Statistics},
	pages        = {351--360},
	organization = {PMLR}
}

@inproceedings{schulman2015trust,
	title        = {Trust region policy optimization},
	author       = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
	year         = 2015,
	booktitle    = {International conference on machine learning},
	pages        = {1889--1897},
	organization = {PMLR}
}

@inproceedings{mnih2016asynchronous,
	title        = {Asynchronous methods for deep reinforcement learning},
	author       = {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	year         = 2016,
	booktitle    = {International conference on machine learning},
	pages        = {1928--1937},
	organization = {PMLR}
}

@article{teh2016consistency,
	title        = {Consistency and fluctuations for stochastic gradient Langevin dynamics},
	author       = {Teh, Yee Whye and Thiery, Alexandre H and Vollmer, Sebastian J},
	year         = 2016,
	journal      = {Journal of Machine Learning Research},
	publisher    = {Journal of Machine Learning Research},
	volume       = 17
}

@inproceedings{van2016deep,
	title        = {Deep reinforcement learning with double q-learning},
	author       = {Van Hasselt, Hado and Guez, Arthur and Silver, David},
	year         = 2016,
	booktitle    = {Proceedings of the AAAI conference on artificial intelligence},
	volume       = 30,
	number       = 1
}

@article{schulman2017proximal,
	title        = {Proximal policy optimization algorithms},
	author       = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1707.06347}
}

@inproceedings{ei_regret,
	title        = {Regret for expected improvement over the best-observed value and stopping condition},
	author       = {Nguyen, Vu and Gupta, Sunil and Rana, Santu and Li, Cheng and Venkatesh, Svetha},
	year         = 2017,
	booktitle    = {Asian Conference on Machine Learning},
	pages        = {279--294},
	organization = {PMLR}
}

@article{berkenkamp2017safe,
	title        = {Safe model-based reinforcement learning with stability guarantees},
	author       = {Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela P and Krause, Andreas},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1705.08551}
}

@article{chua2018deep,
	title        = {Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
	author       = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
	year         = 2018,
	journal      = {Advances in neural information processing systems},
	volume       = 31
}

@inproceedings{koller2018learning,
	title        = {Learning-based model predictive control for safe exploration},
	author       = {Koller, Torsten and Berkenkamp, Felix and Turchetta, Matteo and Krause, Andreas},
	year         = 2018,
	booktitle    = {2018 IEEE conference on decision and control (CDC)},
	pages        = {6059--6066},
	organization = {IEEE}
}

@book{sutton2018reinforcement,
	title        = {Reinforcement learning: An introduction},
	author       = {Sutton, Richard S and Barto, Andrew G},
	year         = 2018,
	publisher    = {MIT press}
}

@inproceedings{haarnoja2018soft,
	title        = {Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
	author       = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	year         = 2018,
	booktitle    = {International conference on machine learning},
	pages        = {1861--1870},
	organization = {PMLR}
}

@article{ma2019sampling,
	title        = {Sampling can be faster than optimization},
	author       = {Ma, Yi-An and Chen, Yuansi and Jin, Chi and Flammarion, Nicolas and Jordan, Michael I},
	year         = 2019,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = 116,
	number       = 42,
	pages        = {20881--20885}
}

@article{curi2020efficient,
	title        = {Efficient model-based reinforcement learning through optimistic policy search and planning},
	author       = {Curi, Sebastian and Berkenkamp, Felix and Krause, Andreas},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.08684}
}

@book{mml,
	title        = {Mathematics for machine learning},
	author       = {Deisenroth, Marc Peter and Faisal, A Aldo and Ong, Cheng Soon},
	year         = 2020,
	publisher    = {Cambridge University Press}
}

@article{mohamed2020monte,
	title        = {Monte Carlo Gradient Estimation in Machine Learning.},
	author       = {Mohamed, Shakir and Rosca, Mihaela and Figurnov, Michael and Mnih, Andriy},
	year         = 2020,
	journal      = {J. Mach. Learn. Res.},
	volume       = 21,
	number       = 132,
	pages        = {1--62}
}
