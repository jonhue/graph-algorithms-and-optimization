% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Summary of Notation}

\begin{fullwidth}
We follow these general rules: \begin{itemize}[noitemsep]
    \item uppercase italic for constants $N$
    \item lowercase italic for indices $i$ and scalar variables $x$
    \item lowercase italic bold for vectors $\vx$
    \item uppercase italic bold for matrices $\mM$
    \item uppercase italic for random variables $X$
    \item uppercase bold for random vectors $\rX$
    \item uppercase italic for sets $\sA$
    % \item uppercase calligraphy for spaces (usually infinite sets) $\spA$
\end{itemize}

\begin{longtable}{p{2.5cm}l}
   $\defeq$ & equality by definition \\
   iff & if and only if \\
%   $\approx$ & approximately equals \\
%   $\propto$ & proportional to \\
   $\Nat$ & set of natural numbers $\{1, 2, \dots\}$ \\
   $\Nat_0$ & set of natural numbers, including $0$, $\Nat \cup \{0\}$ \\
   $\R$ & set of real numbers \\
   $\C$ & set of complex numbers \\
   $[m]$ & set of natural numbers from $1$ to $m$, $\{1, 2, \dots, m-1, m\}$ \\
%   $i:j$ & subset of natural numbers between $i$ and $j$, $\{i, i+1, \dots, j-1, j\}$ \\
   $(a,b]$ & real interval between $a$ and $b$ including $b$ but not including $a$ \\
   $f : \sA \to : \sB$ & function $f$ from elements of set $\sA$ to elements of set $\sB$ \\
   $\Ind{predicate}$ & indicator function ($\Ind{predicate} \defeq 1$ if the $predicate$ is true, else $0$) \\
   $\gets$ & assignment \\
\end{longtable}

\vspace{0cm}\section*{\smallcaps{Linear Algebra}}\vspace{-0.5cm}
\begin{longtable}{p{2.5cm}l}
   $\sS^n$ & set of symmetric $n \times n$ matrices \\
   $\sS_+^n$ & set of symmetric and positive semi-definite $n \times n$ matrices \\
   $\sS_{++}^n$ & set of symmetric and positive definite $n \times n$ matrices \\
   $\mA \preceq \mB$ & Loewner order on symmetric matrices, $\forall \vx \in \R^n: \trans{\vx}\mA\vx \leq \trans{\vx}\mB\vx$ \\
   \addlinespace
   $\vx \perp \vy$ & $\vx$ and $\vy$ are orthogonal, i.e., $\trans{\vx}\vy = 0$ \\
   $\vx \perp \sW$ & $\vx$ is orthogonal to every vector $\vy$ in subspace $\sW$ \\
   $\compl{\sW}$ & orthogonal complement of subspace $\sW$, $\{\vx \in \R^n \mid \vx \perp \sW\}$ \\
   $\vspan\{\vx_1, \dots, \vx_n\}$ & smallest subspace containing $\vx_1, \dots, \vx_n$ \\
   $\dim(\sW)$ & number of vectors in a basis of a subspace $\sW$ \\
   \addlinespace
   $\vOne_\sS$ & vector such that $\vOne_\sS(i) = \Ind{i \in \sS}$ \\
   $\trans{\mA}$ & transpose of matrix $\mA$ \\
   $\inv{\mA}$ & inverse of matrix $\mA$ \\
   $\pinv{\mA}$ & pseudoinverse of matrix $\mA$ \\
   $\mA^{\nicefrac{1}{2}}$ & square root of symmetric positive semi-definite matrix $\mA$ \\
   $\mPi_\mA$ & orthogonal projection to $\compl{(\ker{\mA})}$ \\
   \addlinespace
   $\nnz{\mA}$ & number of non-zero entries of $\mA$ \\
   $\tr{\mA}$ & trace of $\mA$, $\sum_i \mA(i,i)$ \\
   $\diag_{i\in\sI}\{a_i\}$ & diagonal matrix with elements $a_i$, indexed according to the set $\sI$ \\
   $\ker\mA$ & kernel (or null space) of $\mA$, $\{\vx \in \R^n \mid \mA\vx = \vZero\}$ \\
   $\im\mA$ & image of $\mA$, $\vspan\{\mA(:,i)\}_{i\in[n]}$ \\
   $\lambda_i(\mA)$ & $i$-th smallest eigenvalue of $\mA$ \\
   $\norm{\mA}_{\alpha\to\beta}$ & matrix norm of $\mA$ induced by norms $\norm{\cdot}_\alpha$ and $\norm{\cdot}_\beta$ \\
\end{longtable}

\vspace{0.5cm}\section*{\smallcaps{Probability}}\vspace{-0.5cm}
\begin{longtable}{p{2.5cm}l}
   $\Pr{X = x}$ & probability of a random variable $X$ taking on the value $x$ \\
   $X \sim F$ & random variable $X$ follows the distribution $F$ \\
   $x \sim F$ & value $x$ is sampled according to distribution $F$ \\
  $X \perp Y$ & random variable $X$ is independent of random variable $Y$ \\
  $X \perp Y \mid Z$ & \makecell[tl]{random variable $X$ is conditionally independent of random variable $Y$ \\ given random variable $Z$} \\
   $\E{X}$ & expected value of random variable $X$ \\
%   $\E[x \sim X]{f(x)}$ & expected value of the random variable $f(X)$, $\E{f(X)}$ \\
  $\Var{X}$ & variance of random variable $X$ \\
%   $\Cov{X,Y}$ & covariance of random variable $X$ and random variable $Y$ \\
%   $\Delta^{\spA}$ & set of all probability distributions over the set $\spA$ \\
    \addlinespace
   $\mW \in \R^{|\sV|\times|\sV|}$ & transition matrix of random walk, $\mA\inv{\mD} = \mI - \mD^{\nicefrac{1}{2}}\mN\mD^{-\nicefrac{1}{2}}$ \\
   $\Tilde{\mW} \in \R^{|\sV|\times|\sV|}$ & transition matrix of lazy random walk, $\frac{\mI}{2} + \frac{\mW}{2} = \mI - \frac{1}{2}\mD^{\nicefrac{1}{2}}\mN\mD^{-\nicefrac{1}{2}}$ \\
   $\vp_t \in \R^{|\sV|}$ & probability distribution of a random walk at time $t$, $\mW^t\vp_0$ \\
\end{longtable}

\vspace{0.5cm}\section*{\smallcaps{Analysis}}\vspace{-0.5cm}
\begin{longtable}{p{2.5cm}l}
   $\grad f(\vx) \in \R^{n \times 1}$ & gradient of a function $f$ at a point $\vx$, $\trans{\begin{bmatrix}
        \pdv{f(\vx)}{\vx(1)} & \cdots & \pdv{f(\vx)}{\vx(n)}
    \end{bmatrix}}$ \\
   $[\vx,\vy]$ & set of convex combinations of $\vx$ and $\vy$, $\{\theta\vx + (1-\theta)\vy \mid \theta\in[0,1]\}$ \\
   $D f(\vx)[\vd]$ & directional derivative of $f$ at $\vx$ in direction $\vd$, $\lim_{\lambda \to 0} \frac{f(\vx + \lambda\vd) - f(\vx)}{\lambda}$ \\
   $D \vg(\vx) \in \R^{m \times n}$ & Jacobian of vector-valued function $\vg: \R^n \to \R^m$, $\begin{bmatrix}
        \pdv{\vg(\vx)}{\vx(1)} & \cdots & \pdv{\vg(\vx)}{\vx(n)}
    \end{bmatrix}$ \\
   $\mH_f(\vx) \in \R^{n \times n}$ & Hessian of $f$, $\trans{(D \grad f(\vx))}$ \\
   \addlinespace
   $\mathrm{epi}(f)$ & epigraph of a function $f$, $\{(\vx,y) \mid f(\vx) \leq y\} \subseteq \R^{n+1}$ \\
   $\sS_\alpha(f)$ & $\alpha$-sub-level set of a function $f$, $\{\vx \in \sS \mid f(\vx) \leq \alpha\}$ \\
   $\sL_\alpha(f)$ & $\alpha$-level set of a function $f$, $\{\vx \in \sS \mid f(\vx) = \alpha\}$ \\
\end{longtable}

\vspace{0.5cm}\section*{\smallcaps{Graphs}}\vspace{-0.5cm}
\begin{longtable}{p{2.5cm}l}
   $\sV$ & set of vertices \\
   $\sE$ & set of edges \\
   $n$ & number of vertices, $|\sV|$ \\
   $m$ & number of edges, $|\sE|$ \\
   \addlinespace
   $G[\sX]$ & subgraph of $G$ induced by $\sX \subseteq \sV$ \\
   $u \sim v$ & vertices $u$ and $v$ are adjacent \\
   $\deg(v)$ & degree of vertex $v$ \\
   \addlinespace
   $\vr \in \R^{|\sE|}$ & resistances \\
   $\vw \in \R^{|\sE|}$ & weights, $\nicefrac{1}{\vr(e)}$ \\
   $\vd \in \R^{|\sV|}$ & weighted degrees, $\sum_{\{u,v\} \in \sE} \vw(\{u,v\})$ \\
   $\Tilde{\mA} \in \R^{|\sV|\times|\sV|}$ & adjacency matrix \\
   $\mA \in \R^{|\sV|\times|\sV|}$ & weighted adjacency matrix \\
   $\mB \in \R^{|\sV|\times|\sE|}$ & incidence matrix \\
   $\mR \in \R^{|\sE|\times|\sE|}$ & diagonal matrix of resistances, $\diag\{\vr(e)\}_{e \in \sE}$ \\
   $\mW \in \R^{|\sE|\times|\sE|}$ & diagonal matrix of weights, $\diag\{\vw(e)\}_{e \in \sE}$ \\
   $\mD \in \R^{|\sV|\times|\sV|}$ & diagonal matrix of weighted degrees, $\diag\{\vw(v)\}_{v \in \sV}$ \\
   $\mL \in \R^{|\sV|\times|\sV|}$ & Laplacian matrix, $\mB\mR^{-1}\trans{\mB} = \mB\mW\trans{\mB} = \mD - \mA$ \\
   \addlinespace
   $\vol(\sS)$ & volume of a set of vertices $\sS$, $\sum_{v \in \sS} \vd(v) = \trans{\vOne_\sS}\mD\vOne_\sS$ \\
   $c(\sS)$ & value of a cut $\sS$, $\sum_{\{a,b\} \in \sE:\ a \in \sS,\ b \in \sV \setminus \sS} \vw(\{a,b\}) = \trans{\vOne_\sS}\mL\vOne_\sS$ \\
   $\phi(\sS)$ & conductance of a cut $\sS$, $\frac{c(\sS)}{\min\{\vol(\sS), \vol(\sV \setminus \sS)\}}$ \\
   $\phi(G)$ & conductance of a graph $G$, $\min_{\emptyset \subset \sS \subset \sV} \phi(S)$ \\
   $\sigma(\sS)$ & sparsity of a cut $\sS$, $\frac{c(\sS)}{\min\{|\sS|, |\sV \setminus \sS|\}}$ \\
   $\sigma(G)$ & sparsity of a graph $G$, $\min_{\emptyset \subset \sS \subset \sV} \sigma(S)$ \\
   \addlinespace
   $K_n$ & unit weight complete graph on $n$ vertices \\
   $P_n$ & unit weight path graph on $n$ vertices \\
   $T_d$ & unit weight complete binary tree with $d$ levels \\
   $G_{i,j}$ & unit weight graph with single edge $\{i,j\}$ \\
   $G^{i,j}$ & subgraph of $G$ consisting of the shortest $i,j$ path \\
\end{longtable}

\vspace{0.5cm}\section*{\smallcaps{Flows}}\vspace{-0.5cm}
\begin{longtable}{p{2.5cm}l}
   $\vx \in \R^{|\sV|}$ & voltages \\
   $\vx(e)$ & voltage difference of edge $e = \{u,v\}$, $\vx(u) - \vx(v)$ \\
   $\vf \in \R^{|\sE|}$ & flow \\
   $\vd \in \R^{|\sV|}$ & demands, modeling the net flow \\
   \addlinespace
   $\elx \in \R^{|\sV|}$ & electrical voltages \\
   $\elx_{a,b} \in \R^{|\sV|}$ & electrical voltages routing demands $\vOne_b - \vOne_a$ \\
   $\ef \in \R^{|\sE|}$ & electrical flow \\
   $\e(\ef), \e(\elx), \e(\vd)$ & electrical energy, $\trans{\ef}\trans{\mB}\elx = \trans{\ef}\mR\ef = \trans{\elx}\mL\elx = \trans{\vd}\vx = \trans{\vd}\pinv{\mL}\vd$ \\
\end{longtable}
\end{fullwidth}
